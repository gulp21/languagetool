Sun Oct 22 17:41:32 CEST 2017 create_training_files
/tmp/ad_add
5652 lines
3648 ad
2013 add
/tmp/ad_add_training
4522 lines
2916 ad
1614 add
/tmp/ad_add_validate
1130 lines
732 ad
399 add
generate /tmp/ad_add_training.py, /tmp/ad_add_validate.py
:compileJava UP-TO-DATE
:processResources UP-TO-DATE
:classes UP-TO-DATE
:createNGramDatabase
Reading /tmp/ad_add_training
Tokenizing
undersampling to 905
/tmp/ad_add_training.pycreated
Reading /tmp/ad_add_validate
Tokenizing
undersampling to 246
/tmp/ad_add_validate.pycreated

BUILD SUCCESSFUL

Total time: 6.025 secs

This build could be faster, please consider using the Gradle Daemon: https://docs.gradle.org/2.10/userguide/gradle_daemon.html
Sun Oct 22 17:41:48 CEST 2017 create_classifier
{'dictionary_path': 'res_training/eng/embedding/dictionary.txt', 'embedding_path': 'res_training/eng/embedding/final_embeddings.txt', 'batch_size': 1000, 'use_flex_hidden_layer': False, 'num_inputs': 4, 'self': <__main__.NeuralNetwork object at 0x2b94582aea58>, 'num_outputs': 2, 'epochs': 3000, 'training_data_file': '/tmp/ad_add_training.py'}
embedding shape (42122, 64)
/tmp/ad_add_training.py loaded, containing 1810 entries, class distribution: [905 905]
Steps: 3000, 1 steps in 3000 epochs
epoch 0, training accuracy 0.495028
epoch 10, training accuracy 0.507182
epoch 20, training accuracy 0.520994
epoch 30, training accuracy 0.535912
epoch 40, training accuracy 0.547514
epoch 50, training accuracy 0.562431
epoch 60, training accuracy 0.576243
epoch 70, training accuracy 0.590055
epoch 80, training accuracy 0.598895
epoch 90, training accuracy 0.610497
epoch 100, training accuracy 0.619889
epoch 110, training accuracy 0.627624
epoch 120, training accuracy 0.631492
epoch 130, training accuracy 0.639226
epoch 140, training accuracy 0.651934
epoch 150, training accuracy 0.658564
epoch 160, training accuracy 0.672376
epoch 170, training accuracy 0.680663
epoch 180, training accuracy 0.695028
epoch 190, training accuracy 0.704420
epoch 200, training accuracy 0.716022
epoch 210, training accuracy 0.725967
epoch 220, training accuracy 0.734807
epoch 230, training accuracy 0.741436
epoch 240, training accuracy 0.749171
epoch 250, training accuracy 0.751934
epoch 260, training accuracy 0.758011
epoch 270, training accuracy 0.768508
epoch 280, training accuracy 0.776243
epoch 290, training accuracy 0.785635
epoch 300, training accuracy 0.792818
epoch 310, training accuracy 0.799448
epoch 320, training accuracy 0.806630
epoch 330, training accuracy 0.811602
epoch 340, training accuracy 0.817127
epoch 350, training accuracy 0.819889
epoch 360, training accuracy 0.822652
epoch 370, training accuracy 0.830387
epoch 380, training accuracy 0.834254
epoch 390, training accuracy 0.839779
epoch 400, training accuracy 0.845304
epoch 410, training accuracy 0.847514
epoch 420, training accuracy 0.850276
epoch 430, training accuracy 0.855249
epoch 440, training accuracy 0.858564
epoch 450, training accuracy 0.861878
epoch 460, training accuracy 0.863536
epoch 470, training accuracy 0.866298
epoch 480, training accuracy 0.869613
epoch 490, training accuracy 0.873481
epoch 500, training accuracy 0.875138
epoch 510, training accuracy 0.876243
epoch 520, training accuracy 0.877901
epoch 530, training accuracy 0.878453
epoch 540, training accuracy 0.879558
epoch 550, training accuracy 0.882320
epoch 560, training accuracy 0.884530
epoch 570, training accuracy 0.884530
epoch 580, training accuracy 0.885635
epoch 590, training accuracy 0.886188
epoch 600, training accuracy 0.887845
epoch 610, training accuracy 0.888950
epoch 620, training accuracy 0.890055
epoch 630, training accuracy 0.891713
epoch 640, training accuracy 0.892818
epoch 650, training accuracy 0.893923
epoch 660, training accuracy 0.894475
epoch 670, training accuracy 0.895028
epoch 680, training accuracy 0.895028
epoch 690, training accuracy 0.895028
epoch 700, training accuracy 0.895580
epoch 710, training accuracy 0.896685
epoch 720, training accuracy 0.897790
epoch 730, training accuracy 0.898343
epoch 740, training accuracy 0.899448
epoch 750, training accuracy 0.900000
epoch 760, training accuracy 0.901657
epoch 770, training accuracy 0.902210
epoch 780, training accuracy 0.903315
epoch 790, training accuracy 0.904420
epoch 800, training accuracy 0.907182
epoch 810, training accuracy 0.909392
epoch 820, training accuracy 0.910497
epoch 830, training accuracy 0.912155
epoch 840, training accuracy 0.912707
epoch 850, training accuracy 0.914365
epoch 860, training accuracy 0.914917
epoch 870, training accuracy 0.915470
epoch 880, training accuracy 0.916575
epoch 890, training accuracy 0.916575
epoch 900, training accuracy 0.916575
epoch 910, training accuracy 0.916575
epoch 920, training accuracy 0.916575
epoch 930, training accuracy 0.917680
epoch 940, training accuracy 0.918232
epoch 950, training accuracy 0.919890
epoch 960, training accuracy 0.919890
epoch 970, training accuracy 0.919890
epoch 980, training accuracy 0.919890
epoch 990, training accuracy 0.920994
epoch 1000, training accuracy 0.922099
epoch 1010, training accuracy 0.922099
epoch 1020, training accuracy 0.921547
epoch 1030, training accuracy 0.922652
epoch 1040, training accuracy 0.922099
epoch 1050, training accuracy 0.922099
epoch 1060, training accuracy 0.923204
epoch 1070, training accuracy 0.924862
epoch 1080, training accuracy 0.925414
epoch 1090, training accuracy 0.925414
epoch 1100, training accuracy 0.925414
epoch 1110, training accuracy 0.924309
epoch 1120, training accuracy 0.926519
epoch 1130, training accuracy 0.927624
epoch 1140, training accuracy 0.927624
epoch 1150, training accuracy 0.927624
epoch 1160, training accuracy 0.928177
epoch 1170, training accuracy 0.928177
epoch 1180, training accuracy 0.928729
epoch 1190, training accuracy 0.929834
epoch 1200, training accuracy 0.929834
epoch 1210, training accuracy 0.929834
epoch 1220, training accuracy 0.930387
epoch 1230, training accuracy 0.930387
epoch 1240, training accuracy 0.930939
epoch 1250, training accuracy 0.931492
epoch 1260, training accuracy 0.931492
epoch 1270, training accuracy 0.931492
epoch 1280, training accuracy 0.931492
epoch 1290, training accuracy 0.932044
epoch 1300, training accuracy 0.932044
epoch 1310, training accuracy 0.933149
epoch 1320, training accuracy 0.933702
epoch 1330, training accuracy 0.933702
epoch 1340, training accuracy 0.933702
epoch 1350, training accuracy 0.933702
epoch 1360, training accuracy 0.933702
epoch 1370, training accuracy 0.933149
epoch 1380, training accuracy 0.933149
epoch 1390, training accuracy 0.932597
epoch 1400, training accuracy 0.932597
epoch 1410, training accuracy 0.932597
epoch 1420, training accuracy 0.932597
epoch 1430, training accuracy 0.932597
epoch 1440, training accuracy 0.933149
epoch 1450, training accuracy 0.934254
epoch 1460, training accuracy 0.934807
epoch 1470, training accuracy 0.935359
epoch 1480, training accuracy 0.935912
epoch 1490, training accuracy 0.936464
epoch 1500, training accuracy 0.937017
epoch 1510, training accuracy 0.937017
epoch 1520, training accuracy 0.937569
epoch 1530, training accuracy 0.938122
epoch 1540, training accuracy 0.938674
epoch 1550, training accuracy 0.938674
epoch 1560, training accuracy 0.939227
epoch 1570, training accuracy 0.939227
epoch 1580, training accuracy 0.939779
epoch 1590, training accuracy 0.940332
epoch 1600, training accuracy 0.940332
epoch 1610, training accuracy 0.940332
epoch 1620, training accuracy 0.940332
epoch 1630, training accuracy 0.940332
epoch 1640, training accuracy 0.940332
epoch 1650, training accuracy 0.940332
epoch 1660, training accuracy 0.940332
epoch 1670, training accuracy 0.941436
epoch 1680, training accuracy 0.941989
epoch 1690, training accuracy 0.942541
epoch 1700, training accuracy 0.942541
epoch 1710, training accuracy 0.941989
epoch 1720, training accuracy 0.943094
epoch 1730, training accuracy 0.943094
epoch 1740, training accuracy 0.943094
epoch 1750, training accuracy 0.943094
epoch 1760, training accuracy 0.943646
epoch 1770, training accuracy 0.943646
epoch 1780, training accuracy 0.943646
epoch 1790, training accuracy 0.943646
epoch 1800, training accuracy 0.943646
epoch 1810, training accuracy 0.943646
epoch 1820, training accuracy 0.943646
epoch 1830, training accuracy 0.943646
epoch 1840, training accuracy 0.944199
epoch 1850, training accuracy 0.944199
epoch 1860, training accuracy 0.945304
epoch 1870, training accuracy 0.945304
epoch 1880, training accuracy 0.945304
epoch 1890, training accuracy 0.945856
epoch 1900, training accuracy 0.945856
epoch 1910, training accuracy 0.946409
epoch 1920, training accuracy 0.946961
epoch 1930, training accuracy 0.947514
epoch 1940, training accuracy 0.947514
epoch 1950, training accuracy 0.947514
epoch 1960, training accuracy 0.947514
epoch 1970, training accuracy 0.948066
epoch 1980, training accuracy 0.948066
epoch 1990, training accuracy 0.948066
epoch 2000, training accuracy 0.948066
epoch 2010, training accuracy 0.947514
epoch 2020, training accuracy 0.948066
epoch 2030, training accuracy 0.948619
epoch 2040, training accuracy 0.948619
epoch 2050, training accuracy 0.948619
epoch 2060, training accuracy 0.948619
epoch 2070, training accuracy 0.949171
epoch 2080, training accuracy 0.949171
epoch 2090, training accuracy 0.949171
epoch 2100, training accuracy 0.949171
epoch 2110, training accuracy 0.949171
epoch 2120, training accuracy 0.949724
epoch 2130, training accuracy 0.949724
epoch 2140, training accuracy 0.949724
epoch 2150, training accuracy 0.950276
epoch 2160, training accuracy 0.950829
epoch 2170, training accuracy 0.951381
epoch 2180, training accuracy 0.951381
epoch 2190, training accuracy 0.951381
epoch 2200, training accuracy 0.951381
epoch 2210, training accuracy 0.951381
epoch 2220, training accuracy 0.951381
epoch 2230, training accuracy 0.951381
epoch 2240, training accuracy 0.950829
epoch 2250, training accuracy 0.950829
epoch 2260, training accuracy 0.950829
epoch 2270, training accuracy 0.951381
epoch 2280, training accuracy 0.951934
epoch 2290, training accuracy 0.951934
epoch 2300, training accuracy 0.952486
epoch 2310, training accuracy 0.952486
epoch 2320, training accuracy 0.953591
epoch 2330, training accuracy 0.953591
epoch 2340, training accuracy 0.953591
epoch 2350, training accuracy 0.953591
epoch 2360, training accuracy 0.954144
epoch 2370, training accuracy 0.954144
epoch 2380, training accuracy 0.954696
epoch 2390, training accuracy 0.954696
epoch 2400, training accuracy 0.954696
epoch 2410, training accuracy 0.954696
epoch 2420, training accuracy 0.954696
epoch 2430, training accuracy 0.955801
epoch 2440, training accuracy 0.955801
epoch 2450, training accuracy 0.955801
epoch 2460, training accuracy 0.956354
epoch 2470, training accuracy 0.956354
epoch 2480, training accuracy 0.956906
epoch 2490, training accuracy 0.956906
epoch 2500, training accuracy 0.956906
epoch 2510, training accuracy 0.956906
epoch 2520, training accuracy 0.956906
epoch 2530, training accuracy 0.956906
epoch 2540, training accuracy 0.956906
epoch 2550, training accuracy 0.957459
epoch 2560, training accuracy 0.957459
epoch 2570, training accuracy 0.958011
epoch 2580, training accuracy 0.958011
epoch 2590, training accuracy 0.958011
epoch 2600, training accuracy 0.958011
epoch 2610, training accuracy 0.958011
epoch 2620, training accuracy 0.958011
epoch 2630, training accuracy 0.958011
epoch 2640, training accuracy 0.958011
epoch 2650, training accuracy 0.958011
epoch 2660, training accuracy 0.958011
epoch 2670, training accuracy 0.958011
epoch 2680, training accuracy 0.958011
epoch 2690, training accuracy 0.958011
epoch 2700, training accuracy 0.958011
epoch 2710, training accuracy 0.958564
epoch 2720, training accuracy 0.958564
epoch 2730, training accuracy 0.958564
epoch 2740, training accuracy 0.958564
epoch 2750, training accuracy 0.958564
epoch 2760, training accuracy 0.958564
epoch 2770, training accuracy 0.958564
epoch 2780, training accuracy 0.958564
epoch 2790, training accuracy 0.958564
epoch 2800, training accuracy 0.959116
epoch 2810, training accuracy 0.959116
epoch 2820, training accuracy 0.959116
epoch 2830, training accuracy 0.959116
epoch 2840, training accuracy 0.959669
epoch 2850, training accuracy 0.959669
epoch 2860, training accuracy 0.959669
epoch 2870, training accuracy 0.959669
epoch 2880, training accuracy 0.959669
epoch 2890, training accuracy 0.959669
epoch 2900, training accuracy 0.959669
epoch 2910, training accuracy 0.959669
epoch 2920, training accuracy 0.959669
epoch 2930, training accuracy 0.960221
epoch 2940, training accuracy 0.960221
epoch 2950, training accuracy 0.960221
epoch 2960, training accuracy 0.960221
epoch 2970, training accuracy 0.960221
epoch 2980, training accuracy 0.960221
epoch 2990, training accuracy 0.960221
epoch 3000, training accuracy 0.960221
/tmp/ad_add_validate.py loaded, containing 492 entries, class distribution: [246 246]
correct: [204, 210]
incorrect: [3, 5]
accuracy: [0.9855072463768116, 0.9767441860465116]
unclassified: [39, 31]
total accuracy: [0.8292682926829268, 0.8536585365853658]
Sun Oct 22 17:42:10 CEST 2017 finished, res_training/eng/ad_add
Mon Oct 23 06:45:13 CEST 2017 create_training_files
/tmp/ad_add
5652 lines
3648 ad
2013 add
/tmp/ad_add_training
4522 lines
2906 ad
1624 add
/tmp/ad_add_validate
1130 lines
742 ad
389 add
generate /tmp/ad_add_training.py, /tmp/ad_add_validate.py
:compileJava UP-TO-DATE
:processResources UP-TO-DATE
:classes UP-TO-DATE
:createNGramDatabase
Reading /tmp/ad_add_training
Tokenizing
undersampling to 915
/tmp/ad_add_training.pycreated
Reading /tmp/ad_add_validate
Tokenizing
undersampling to 236
/tmp/ad_add_validate.pycreated

BUILD SUCCESSFUL

Total time: 5.2 secs

This build could be faster, please consider using the Gradle Daemon: https://docs.gradle.org/2.10/userguide/gradle_daemon.html
Mon Oct 23 06:45:28 CEST 2017 create_classifier
{'num_inputs': 4, 'num_outputs': 2, 'embedding_path': 'res_training/eng/embedding/final_embeddings.txt', 'self': <__main__.NeuralNetwork object at 0x2b5bdc93fa58>, 'dictionary_path': 'res_training/eng/embedding/dictionary.txt', 'use_flex_hidden_layer': False, 'epochs': 3000, 'training_data_file': '/tmp/ad_add_training.py', 'batch_size': 1000}
embedding shape (42122, 64)
/tmp/ad_add_training.py loaded, containing 1830 entries, class distribution: [915 915]
Steps: 3000, 1 steps in 3000 epochs
epoch 0, training accuracy 0.446995
epoch 10, training accuracy 0.453552
epoch 20, training accuracy 0.459016
epoch 30, training accuracy 0.465574
epoch 40, training accuracy 0.473770
epoch 50, training accuracy 0.485792
epoch 60, training accuracy 0.497268
epoch 70, training accuracy 0.510383
epoch 80, training accuracy 0.522404
epoch 90, training accuracy 0.536612
epoch 100, training accuracy 0.554098
epoch 110, training accuracy 0.571585
epoch 120, training accuracy 0.584153
epoch 130, training accuracy 0.595082
epoch 140, training accuracy 0.606011
epoch 150, training accuracy 0.620765
epoch 160, training accuracy 0.639344
epoch 170, training accuracy 0.651366
epoch 180, training accuracy 0.662295
epoch 190, training accuracy 0.678142
epoch 200, training accuracy 0.695628
epoch 210, training accuracy 0.701093
epoch 220, training accuracy 0.710929
epoch 230, training accuracy 0.717486
epoch 240, training accuracy 0.727322
epoch 250, training accuracy 0.734426
epoch 260, training accuracy 0.741530
epoch 270, training accuracy 0.752459
epoch 280, training accuracy 0.758470
epoch 290, training accuracy 0.770492
epoch 300, training accuracy 0.776503
epoch 310, training accuracy 0.783607
epoch 320, training accuracy 0.787978
epoch 330, training accuracy 0.793443
epoch 340, training accuracy 0.796175
epoch 350, training accuracy 0.801639
epoch 360, training accuracy 0.807104
epoch 370, training accuracy 0.810929
epoch 380, training accuracy 0.813115
epoch 390, training accuracy 0.813661
epoch 400, training accuracy 0.816940
epoch 410, training accuracy 0.820219
epoch 420, training accuracy 0.822404
epoch 430, training accuracy 0.824590
epoch 440, training accuracy 0.827869
epoch 450, training accuracy 0.829508
epoch 460, training accuracy 0.831694
epoch 470, training accuracy 0.836066
epoch 480, training accuracy 0.837705
epoch 490, training accuracy 0.839344
epoch 500, training accuracy 0.840437
epoch 510, training accuracy 0.842623
epoch 520, training accuracy 0.844262
epoch 530, training accuracy 0.848087
epoch 540, training accuracy 0.850273
epoch 550, training accuracy 0.851366
epoch 560, training accuracy 0.854098
epoch 570, training accuracy 0.855738
epoch 580, training accuracy 0.858470
epoch 590, training accuracy 0.860109
epoch 600, training accuracy 0.861749
epoch 610, training accuracy 0.862295
epoch 620, training accuracy 0.863388
epoch 630, training accuracy 0.865027
epoch 640, training accuracy 0.866667
epoch 650, training accuracy 0.867760
epoch 660, training accuracy 0.869945
epoch 670, training accuracy 0.871585
epoch 680, training accuracy 0.873224
epoch 690, training accuracy 0.875956
epoch 700, training accuracy 0.877596
epoch 710, training accuracy 0.879235
epoch 720, training accuracy 0.880874
epoch 730, training accuracy 0.882514
epoch 740, training accuracy 0.883607
epoch 750, training accuracy 0.883607
epoch 760, training accuracy 0.884153
epoch 770, training accuracy 0.884699
epoch 780, training accuracy 0.885792
epoch 790, training accuracy 0.886339
epoch 800, training accuracy 0.887432
epoch 810, training accuracy 0.889071
epoch 820, training accuracy 0.889618
epoch 830, training accuracy 0.890164
epoch 840, training accuracy 0.890710
epoch 850, training accuracy 0.890710
epoch 860, training accuracy 0.891257
epoch 870, training accuracy 0.892896
epoch 880, training accuracy 0.895082
epoch 890, training accuracy 0.898361
epoch 900, training accuracy 0.899454
epoch 910, training accuracy 0.899454
epoch 920, training accuracy 0.900000
epoch 930, training accuracy 0.899454
epoch 940, training accuracy 0.902186
epoch 950, training accuracy 0.903279
epoch 960, training accuracy 0.903279
epoch 970, training accuracy 0.904372
epoch 980, training accuracy 0.904918
epoch 990, training accuracy 0.907104
epoch 1000, training accuracy 0.908197
epoch 1010, training accuracy 0.908197
epoch 1020, training accuracy 0.908197
epoch 1030, training accuracy 0.908197
epoch 1040, training accuracy 0.908743
epoch 1050, training accuracy 0.909836
epoch 1060, training accuracy 0.911475
epoch 1070, training accuracy 0.913115
epoch 1080, training accuracy 0.913115
epoch 1090, training accuracy 0.914208
epoch 1100, training accuracy 0.914208
epoch 1110, training accuracy 0.916940
epoch 1120, training accuracy 0.916940
epoch 1130, training accuracy 0.917486
epoch 1140, training accuracy 0.918579
epoch 1150, training accuracy 0.918579
epoch 1160, training accuracy 0.918579
epoch 1170, training accuracy 0.918579
epoch 1180, training accuracy 0.919126
epoch 1190, training accuracy 0.919672
epoch 1200, training accuracy 0.919672
epoch 1210, training accuracy 0.919672
epoch 1220, training accuracy 0.920765
epoch 1230, training accuracy 0.921858
epoch 1240, training accuracy 0.922951
epoch 1250, training accuracy 0.922951
epoch 1260, training accuracy 0.923497
epoch 1270, training accuracy 0.924044
epoch 1280, training accuracy 0.925137
epoch 1290, training accuracy 0.926230
epoch 1300, training accuracy 0.926776
epoch 1310, training accuracy 0.927869
epoch 1320, training accuracy 0.927869
epoch 1330, training accuracy 0.927869
epoch 1340, training accuracy 0.927869
epoch 1350, training accuracy 0.927869
epoch 1360, training accuracy 0.928415
epoch 1370, training accuracy 0.928415
epoch 1380, training accuracy 0.928962
epoch 1390, training accuracy 0.928962
epoch 1400, training accuracy 0.928962
epoch 1410, training accuracy 0.930055
epoch 1420, training accuracy 0.930601
epoch 1430, training accuracy 0.931148
epoch 1440, training accuracy 0.931148
epoch 1450, training accuracy 0.931148
epoch 1460, training accuracy 0.932240
epoch 1470, training accuracy 0.932240
epoch 1480, training accuracy 0.932787
epoch 1490, training accuracy 0.932787
epoch 1500, training accuracy 0.933333
epoch 1510, training accuracy 0.933333
epoch 1520, training accuracy 0.933333
epoch 1530, training accuracy 0.933333
epoch 1540, training accuracy 0.934426
epoch 1550, training accuracy 0.934973
epoch 1560, training accuracy 0.934973
epoch 1570, training accuracy 0.934973
epoch 1580, training accuracy 0.934973
epoch 1590, training accuracy 0.934973
epoch 1600, training accuracy 0.935519
epoch 1610, training accuracy 0.937158
epoch 1620, training accuracy 0.937158
epoch 1630, training accuracy 0.937705
epoch 1640, training accuracy 0.939344
epoch 1650, training accuracy 0.938798
epoch 1660, training accuracy 0.938798
epoch 1670, training accuracy 0.938798
epoch 1680, training accuracy 0.939344
epoch 1690, training accuracy 0.939891
epoch 1700, training accuracy 0.939891
epoch 1710, training accuracy 0.939891
epoch 1720, training accuracy 0.939891
epoch 1730, training accuracy 0.939891
epoch 1740, training accuracy 0.940437
epoch 1750, training accuracy 0.940984
epoch 1760, training accuracy 0.940984
epoch 1770, training accuracy 0.940984
epoch 1780, training accuracy 0.942077
epoch 1790, training accuracy 0.942077
epoch 1800, training accuracy 0.942077
epoch 1810, training accuracy 0.942623
epoch 1820, training accuracy 0.942623
epoch 1830, training accuracy 0.943169
epoch 1840, training accuracy 0.943169
epoch 1850, training accuracy 0.943169
epoch 1860, training accuracy 0.943169
epoch 1870, training accuracy 0.943169
epoch 1880, training accuracy 0.943169
epoch 1890, training accuracy 0.943169
epoch 1900, training accuracy 0.943169
epoch 1910, training accuracy 0.942623
epoch 1920, training accuracy 0.943716
epoch 1930, training accuracy 0.943716
epoch 1940, training accuracy 0.943716
epoch 1950, training accuracy 0.944262
epoch 1960, training accuracy 0.944262
epoch 1970, training accuracy 0.944262
epoch 1980, training accuracy 0.944262
epoch 1990, training accuracy 0.944809
epoch 2000, training accuracy 0.945355
epoch 2010, training accuracy 0.945355
epoch 2020, training accuracy 0.945902
epoch 2030, training accuracy 0.945902
epoch 2040, training accuracy 0.945902
epoch 2050, training accuracy 0.945902
epoch 2060, training accuracy 0.945902
epoch 2070, training accuracy 0.945902
epoch 2080, training accuracy 0.945902
epoch 2090, training accuracy 0.946448
epoch 2100, training accuracy 0.946448
epoch 2110, training accuracy 0.946448
epoch 2120, training accuracy 0.946448
epoch 2130, training accuracy 0.946448
epoch 2140, training accuracy 0.946448
epoch 2150, training accuracy 0.946995
epoch 2160, training accuracy 0.947541
epoch 2170, training accuracy 0.947541
epoch 2180, training accuracy 0.947541
epoch 2190, training accuracy 0.948087
epoch 2200, training accuracy 0.948087
epoch 2210, training accuracy 0.948087
epoch 2220, training accuracy 0.948087
epoch 2230, training accuracy 0.948087
epoch 2240, training accuracy 0.948087
epoch 2250, training accuracy 0.948634
epoch 2260, training accuracy 0.948634
epoch 2270, training accuracy 0.949180
epoch 2280, training accuracy 0.949727
epoch 2290, training accuracy 0.949727
epoch 2300, training accuracy 0.949727
epoch 2310, training accuracy 0.950273
epoch 2320, training accuracy 0.950273
epoch 2330, training accuracy 0.950273
epoch 2340, training accuracy 0.950273
epoch 2350, training accuracy 0.950273
epoch 2360, training accuracy 0.950273
epoch 2370, training accuracy 0.950820
epoch 2380, training accuracy 0.950820
epoch 2390, training accuracy 0.950820
epoch 2400, training accuracy 0.950820
epoch 2410, training accuracy 0.950820
epoch 2420, training accuracy 0.951366
epoch 2430, training accuracy 0.951366
epoch 2440, training accuracy 0.951366
epoch 2450, training accuracy 0.951366
epoch 2460, training accuracy 0.951913
epoch 2470, training accuracy 0.951913
epoch 2480, training accuracy 0.952459
epoch 2490, training accuracy 0.952459
epoch 2500, training accuracy 0.953005
epoch 2510, training accuracy 0.953005
epoch 2520, training accuracy 0.953005
epoch 2530, training accuracy 0.953005
epoch 2540, training accuracy 0.953005
epoch 2550, training accuracy 0.953005
epoch 2560, training accuracy 0.953552
epoch 2570, training accuracy 0.953552
epoch 2580, training accuracy 0.953552
epoch 2590, training accuracy 0.953552
epoch 2600, training accuracy 0.954098
epoch 2610, training accuracy 0.954098
epoch 2620, training accuracy 0.954645
epoch 2630, training accuracy 0.954645
epoch 2640, training accuracy 0.954645
epoch 2650, training accuracy 0.954645
epoch 2660, training accuracy 0.954645
epoch 2670, training accuracy 0.954645
epoch 2680, training accuracy 0.954645
epoch 2690, training accuracy 0.954645
epoch 2700, training accuracy 0.955191
epoch 2710, training accuracy 0.955738
epoch 2720, training accuracy 0.955738
epoch 2730, training accuracy 0.955738
epoch 2740, training accuracy 0.955738
epoch 2750, training accuracy 0.955738
epoch 2760, training accuracy 0.956284
epoch 2770, training accuracy 0.956284
epoch 2780, training accuracy 0.956284
epoch 2790, training accuracy 0.956284
epoch 2800, training accuracy 0.956284
epoch 2810, training accuracy 0.956284
epoch 2820, training accuracy 0.956831
epoch 2830, training accuracy 0.956831
epoch 2840, training accuracy 0.956831
epoch 2850, training accuracy 0.956831
epoch 2860, training accuracy 0.956831
epoch 2870, training accuracy 0.956831
epoch 2880, training accuracy 0.956831
epoch 2890, training accuracy 0.957377
epoch 2900, training accuracy 0.957377
epoch 2910, training accuracy 0.957377
epoch 2920, training accuracy 0.957377
epoch 2930, training accuracy 0.957923
epoch 2940, training accuracy 0.957923
epoch 2950, training accuracy 0.957923
epoch 2960, training accuracy 0.957923
epoch 2970, training accuracy 0.957923
epoch 2980, training accuracy 0.957923
epoch 2990, training accuracy 0.957923
epoch 3000, training accuracy 0.959016
/tmp/ad_add_validate.py loaded, containing 472 entries, class distribution: [236 236]
correct: [202, 217]
incorrect: [2, 3]
accuracy: [0.9901960784313726, 0.9863636363636363]
unclassified: [32, 16]
total accuracy: [0.8559322033898306, 0.9194915254237288]
Mon Oct 23 06:45:50 CEST 2017 finished, res_training/eng/ad_add
